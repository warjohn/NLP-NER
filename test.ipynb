{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2373991",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import torch\n",
    "import random\n",
    "import evaluate\n",
    "import Levenshtein\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "from datasets import Dataset\n",
    "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer, EarlyStoppingCallback, BertTokenizerFast, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b8e8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_entity(text, model, tokenizer):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True).to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "    predictions = torch.argmax(logits, dim=2).squeeze().tolist()\n",
    "\n",
    "    tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"].squeeze())\n",
    "    pred_labels = predictions\n",
    "\n",
    "    filtered_tokens = [\n",
    "        token.replace(\"#\", \"\") \n",
    "        for token, label in zip(tokens, pred_labels)\n",
    "        if label == 1 and token not in tokenizer.all_special_tokens\n",
    "    ]\n",
    "\n",
    "    predicted_entity = \"\".join(filtered_tokens)  # объединяем без пробелов\n",
    "    return predicted_entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab51b592",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"ner_model/checkpoint-2560\"\n",
    "\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-multilingual-cased\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "042f1a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = predict_entity(\"Привет вот мой артикула - JFDBFD-1231\", model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1b4fd26d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'JFDBFD-1231'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
